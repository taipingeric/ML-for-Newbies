{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bm9z7VnUvfaC"
      },
      "source": [
        "# Metric learning for image similarity search\n",
        "\n",
        "**Author:** [Mat Kelcey](https://twitter.com/mat_kelcey)<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sht1c5YSvfaF"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qr5cph2fvfaF"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from collections import defaultdict\n",
        "from PIL import Image\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdL43oMZvfaH"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "ä½¿ç”¨[CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) è³‡æ–™é›†."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHsLy5gjvfaH"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_test_raw = x_test.copy()\n",
        "\n",
        "y_train = np.squeeze(y_train) # (50000, 1) -> (50000)\n",
        "y_test = np.squeeze(y_test)\n",
        "\n",
        "x_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doNRpBTTvfaH"
      },
      "source": [
        "éš¨æ©Ÿé¸æ“‡25å¼µåœ–ç‰‡"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUOTBhiRvfaI"
      },
      "outputs": [],
      "source": [
        "height_width = 32\n",
        "\n",
        "\n",
        "def show_collage(examples):\n",
        "    box_size = height_width + 2\n",
        "    num_rows, num_cols = examples.shape[:2]\n",
        "\n",
        "    collage = Image.new(\n",
        "        mode=\"RGB\",\n",
        "        size=(num_cols * box_size, num_rows * box_size),\n",
        "        color=(250, 250, 250),\n",
        "    )\n",
        "    for row_idx in range(num_rows):\n",
        "        for col_idx in range(num_cols):\n",
        "            array = (np.array(examples[row_idx, col_idx])).astype(np.uint8)\n",
        "            collage.paste(\n",
        "                Image.fromarray(array), (col_idx * box_size, row_idx * box_size)\n",
        "            )\n",
        "\n",
        "    # Double size for visualisation.\n",
        "    collage = collage.resize((2 * num_cols * box_size, 2 * num_rows * box_size))\n",
        "    return collage\n",
        "\n",
        "\n",
        "# Show a collage of 5x5 random images.\n",
        "sample_idxs = np.random.randint(0, 50000, size=(5, 5))\n",
        "examples = x_train[sample_idxs]\n",
        "show_collage(examples)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ä½¿ç”¨transfer learning å‰è™•ç†\n",
        "preprocess = keras.applications.mobilenet_v2.preprocess_input\n",
        "\n",
        "x_train = preprocess(x_train)\n",
        "x_test = preprocess(x_test)"
      ],
      "metadata": {
        "id": "VfdoJNgaHHbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vfVSGq_vfaI"
      },
      "outputs": [],
      "source": [
        "# å»ºæ§‹å„é¡åˆ¥å°æ‡‰å½±åƒä½ç½®\n",
        "class_idx_to_train_idxs = defaultdict(list)\n",
        "for y_train_idx, y in enumerate(y_train):\n",
        "    class_idx_to_train_idxs[y].append(y_train_idx)\n",
        "\n",
        "class_idx_to_test_idxs = defaultdict(list)\n",
        "for y_test_idx, y in enumerate(y_test):\n",
        "    class_idx_to_test_idxs[y].append(y_test_idx)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# key: é¡åˆ¥\n",
        "class_idx_to_test_idxs.keys()"
      ],
      "metadata": {
        "id": "cMkoh2EKx3nP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# value: æ­¤é¡åˆ¥çš„åœ–ç‰‡åœ¨ç¬¬å¹¾å¼µ\n",
        "class_idx_to_test_idxs[0][:5]"
      ],
      "metadata": {
        "id": "SXGYJL4Oya4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ç›®æ¨™ï¼š\n",
        "\n",
        "åœ¨ä¸€å€‹batchä¸­\n",
        "\n",
        "1. æ‹‰è¿‘anchor, positive\n",
        "\n",
        "2. æ‹‰é–‹anchor, negative\n",
        "\n",
        "é€™é‚Šçš„batch sizeè·Ÿé¡åˆ¥å€‹æ•¸ç›¸åŒ e.g: CIFAR10 = 10"
      ],
      "metadata": {
        "id": "j_BnrXph2aVk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJ3UUm_NvfaJ"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "\n",
        "class AnchorPositivePairs(keras.utils.Sequence):\n",
        "    def __init__(self, num_batchs):\n",
        "        self.num_batchs = num_batchs\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_batchs\n",
        "\n",
        "    def __getitem__(self, _idx):\n",
        "        x = np.empty((2, num_classes, height_width, height_width, 3), dtype=np.float32)\n",
        "        # å°‡æ¯å€‹é¡åˆ¥ä¾åºå–å‡º\n",
        "        for class_idx in range(num_classes):\n",
        "            examples_for_class = class_idx_to_train_idxs[class_idx]\n",
        "            # éš¨æ©Ÿé¸æ“‡ anchor, positive ä½ç½®å„ä¸€\n",
        "            anchor_idx = random.choice(examples_for_class)\n",
        "            positive_idx = random.choice(examples_for_class)\n",
        "            # è‹¥å‰›å¥½anchor èˆ‡ positive æ˜¯åŒä¸€å¼µï¼ŒæŒçºŒéš¨æ©Ÿé¸æ“‡\n",
        "            while positive_idx == anchor_idx:\n",
        "                positive_idx = random.choice(examples_for_class)\n",
        "            # å°‡anchor, positive åœ–ç‰‡æ”¾åˆ°å°æ‡‰çš„é¡åˆ¥\n",
        "            x[0, class_idx] = x_train[anchor_idx]\n",
        "            x[1, class_idx] = x_train[positive_idx]\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUcjbfSjvfaK"
      },
      "source": [
        "è¦–è¦ºåŒ–ä¸€å€‹batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIQ06EFxvfaK"
      },
      "outputs": [],
      "source": [
        "examples = AnchorPositivePairs(num_batchs=1)[0]\n",
        "examples = ((examples/2 + 0.5) * 255).astype(int) # -1~1 -> 0~255\n",
        "print(\"examples shape\", examples.shape)\n",
        "show_collage(examples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFhA3f_YvfaL"
      },
      "source": [
        "## Embedding model\n",
        "\n",
        "å®¢è£½åŒ–Modelçš„`train_step`\n",
        "\n",
        "1. å–å‡ºanchor & positive çš„embedding å‘é‡\n",
        "\n",
        "2. è¨ˆç®—anchor & positive å‘é‡å…§ç©"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHZbiC15vfaL"
      },
      "outputs": [],
      "source": [
        "\n",
        "class EmbeddingModel(keras.Model):\n",
        "    def train_step(self, data):\n",
        "        # Note: Workaround for open issue, to be removed.\n",
        "        if isinstance(data, tuple):\n",
        "            data = data[0]\n",
        "        anchors, positives = data[0], data[1]\n",
        "        # data: (2, N, H, W, C)\n",
        "        # anchor, postive: (N, H, W, C)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # è¨ˆç®— anchors, positives çš„ embedding\n",
        "            # anchor, positive embedding: (N, dim)\n",
        "            anchor_embeddings = self(anchors, training=True)\n",
        "            positive_embeddings = self(positives, training=True)\n",
        "\n",
        "            # ç”¨å…§ç©è¨ˆç®—anchors, positives ç›¸ä¼¼åº¦\n",
        "            # similarities: (N, N)\n",
        "            similarities = tf.einsum(\n",
        "                \"ae,pe->ap\", anchor_embeddings, positive_embeddings\n",
        "            )\n",
        "\n",
        "            # ç”¨è¶…åƒæ•¸temperatureåšnormalize\n",
        "            temperature = 0.2\n",
        "            similarities /= temperature\n",
        "\n",
        "            # è§£ç­”ç‚ºNé¡åˆ¥index: [0, 1, 2, ..., num_classes-1]\n",
        "            # è§£ç­”å½¢å¼ç‚ºå°è§’çŸ©é™£\n",
        "            # e.g 3é¡åˆ¥:\n",
        "            # [1, 0, 0]\n",
        "            # [0, 1, 0]\n",
        "            # [0, 0, 1]\n",
        "            sparse_labels = tf.range(num_classes)\n",
        "            loss = self.compiled_loss(sparse_labels, similarities)\n",
        "\n",
        "        # è¨ˆç®—æ¢¯åº¦+æ›´æ–°åƒæ•¸\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "\n",
        "        # æ›´æ–°metrics\n",
        "        self.compiled_metrics.update_state(sparse_labels, similarities)\n",
        "        return {m.name: m.result() for m in self.metrics}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yD7_MCVvfaL"
      },
      "source": [
        "å»ºé€ æ¨¡å‹\n",
        "\n",
        "æŠ½å–ç‰¹å¾µå¾Œå°‡è¼¸å…¥æŠ•å½±è‡³dim=8ç©ºé–“ï¼Œå†normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpKkw2yivfaM"
      },
      "outputs": [],
      "source": [
        "inputs = layers.Input(shape=(height_width, height_width, 3))\n",
        "encoder = keras.applications.MobileNetV2(include_top=False, \n",
        "                                         weights='imagenet',\n",
        "                                         input_shape=(height_width, height_width, 3))\n",
        "x = encoder(inputs)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "embeddings = layers.Dense(units=8, activation=None)(x)\n",
        "embeddings = tf.nn.l2_normalize(embeddings, axis=-1)\n",
        "# ç”¨ä¸Šé¢EmbeddingModelå°è£æ¨¡å‹\n",
        "model = EmbeddingModel(inputs, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "CSKAS0MBJdWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deF7nbt7vfaM"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        ")\n",
        "# 1å€‹epoch 1000 batches\n",
        "history = model.fit(AnchorPositivePairs(num_batchs=1000), \n",
        "                    epochs=20)\n",
        "\n",
        "plt.plot(history.history[\"loss\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights(\"mobilev2_metric_32.h5\")"
      ],
      "metadata": {
        "id": "UbxmQJxuKKuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzbiBIt_vfaM"
      },
      "source": [
        "## Testing\n",
        "\n",
        "1. è¨ˆç®—æ•´å€‹test_setçš„åœ–ç‰‡embedding\n",
        "2. è¨ˆç®—teståœ–ç‰‡å…©å…©é–“çš„ç›¸ä¼¼åº¦ "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -L https://github.com/taipingeric/ML-for-Newbies/releases/download/0.0.1/mobilev2_metric_32.h5 > mobilev2_metric_32.h5"
      ],
      "metadata": {
        "id": "PvB20RY9ig7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(\"mobilev2_metric_32.h5\")"
      ],
      "metadata": {
        "id": "9lTyfSAGdoMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVfO523GvfaM"
      },
      "outputs": [],
      "source": [
        "near_neighbours_per_example = 10\n",
        "\n",
        "embeddings = model.predict(x_test)\n",
        "# è¨ˆç®—åœ–ç‰‡å…©å…©é–“çš„å…§ç©\n",
        "gram_matrix = np.einsum(\"ae,be->ab\", embeddings, embeddings)\n",
        "# è¨ˆç®—æ¯ä¸€ç­†è³‡æ–™ç›¸ä¼¼åº¦æ’åºæœ€é«˜çš„10ç­†çµæœ (å°->å¤§)\n",
        "# æœ€å¤§å€¼å°±æ˜¯è‡ªå·±æœ¬èº« (100%ç›¸ä¼¼)\n",
        "near_neighbours = np.argsort(gram_matrix.T)[:, -(near_neighbours_per_example + 1) :]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.shape, gram_matrix.shape, near_neighbours.shape"
      ],
      "metadata": {
        "id": "V6TYx7aizvGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "    print(near_neighbours[i])"
      ],
      "metadata": {
        "id": "dOPDhaGCz-fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zPDwgsUvfaM"
      },
      "source": [
        "column 0: åŸå§‹æŸ¥è©¢åœ–ç‰‡\n",
        "\n",
        "column 1~10: è³‡æ–™åº«ä¸­æœ€æ¥è¿‘çš„åœ–ç‰‡ ä»¥ç›¸ä¼¼åº¦æ’åºå¤§->å°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Epzi9XW3vfaN"
      },
      "outputs": [],
      "source": [
        "num_collage_examples = 5\n",
        "\n",
        "examples = np.empty(\n",
        "    (\n",
        "        num_collage_examples,\n",
        "        near_neighbours_per_example + 1,\n",
        "        height_width,\n",
        "        height_width,\n",
        "        3,\n",
        "    ),\n",
        "    dtype=np.float32,\n",
        ")\n",
        "for row_idx in range(num_collage_examples):\n",
        "    examples[row_idx, 0] = x_test_raw[row_idx]\n",
        "    anchor_near_neighbours = reversed(near_neighbours[row_idx][:-1])\n",
        "    for col_idx, nn_idx in enumerate(anchor_near_neighbours):\n",
        "        examples[row_idx, col_idx + 1] = x_test_raw[nn_idx]\n",
        "\n",
        "show_collage(examples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nya9paVLvfaN"
      },
      "source": [
        "è¨ˆç®—å„é¡åˆ¥ä¸­ï¼Œæ¯å¼µåœ–ç‰‡èˆ‡æœ€æ¥è¿‘è©²åœ–ç‰‡çš„é¡åˆ¥æ˜¯å¦ç‚ºåŒä¸€å€‹ï¼Œè¨ˆç®—æ··æ·†çŸ©é™£"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnB2-yzVvfaN"
      },
      "outputs": [],
      "source": [
        "confusion_matrix = np.zeros((num_classes, num_classes))\n",
        "\n",
        "# For each class.\n",
        "for class_idx in range(num_classes):\n",
        "    # æŒ‘é¸10ç­†è³‡æ–™\n",
        "    example_idxs = class_idx_to_test_idxs[class_idx][:10]\n",
        "    for y_test_idx in example_idxs:\n",
        "        # è¨ˆç®—èˆ‡è©²åœ–ç‰‡æœ€ç›¸ä¼¼çš„åœ–ç‰‡é¡åˆ¥\n",
        "        for nn_idx in near_neighbours[y_test_idx][:-1]:\n",
        "            nn_class_idx = y_test[nn_idx]\n",
        "            confusion_matrix[class_idx, nn_class_idx] += 1\n",
        "\n",
        "# é¡¯ç¤ºæ··æ·†çŸ©é™£\n",
        "labels = [\n",
        "    \"Airplane\",\n",
        "    \"Automobile\",\n",
        "    \"Bird\",\n",
        "    \"Cat\",\n",
        "    \"Deer\",\n",
        "    \"Dog\",\n",
        "    \"Frog\",\n",
        "    \"Horse\",\n",
        "    \"Ship\",\n",
        "    \"Truck\",\n",
        "]\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix, display_labels=labels)\n",
        "disp.plot(include_values=True, cmap=\"viridis\", ax=None, xticks_rotation=\"vertical\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ref: \n",
        "* [What is metric learning?](http://contrib.scikit-learn.org/metric-learn/introduction.html)\n",
        "* [\"Using crossentropy for metric learning\" tutorial](https://www.youtube.com/watch?v=Jb4Ewl5RzkI)"
      ],
      "metadata": {
        "id": "TY1J7TX8wUCE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPpdt6DUvfaN"
      },
      "source": [
        "Example available on HuggingFace.\n",
        "\n",
        "| Trained Model | Demo |\n",
        "| :--: | :--: |\n",
        "| [![Generic badge](https://img.shields.io/badge/ğŸ¤—%20Model-Cifar10%20Metric%20Learning-black.svg)](https://huggingface.co/keras-io/cifar10_metric_learning) | [![Generic badge](https://img.shields.io/badge/ğŸ¤—%20Spaces-Metric%20Learning%20for%20Image%20Similarity%20Search-black.svg)](https://huggingface.co/spaces/keras-io/metric-learning-image-similarity-search) |"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}