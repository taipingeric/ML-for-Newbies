{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bm9z7VnUvfaC"
      },
      "source": [
        "# Metric learning for image similarity search\n",
        "\n",
        "**Author:** [Mat Kelcey](https://twitter.com/mat_kelcey)<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sht1c5YSvfaF"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qr5cph2fvfaF"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from collections import defaultdict\n",
        "from PIL import Image\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdL43oMZvfaH"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "使用[CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) 資料集."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHsLy5gjvfaH"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_test_raw = x_test.copy()\n",
        "\n",
        "y_train = np.squeeze(y_train) # (50000, 1) -> (50000)\n",
        "y_test = np.squeeze(y_test)\n",
        "\n",
        "x_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doNRpBTTvfaH"
      },
      "source": [
        "隨機選擇25張圖片"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUOTBhiRvfaI"
      },
      "outputs": [],
      "source": [
        "height_width = 32\n",
        "\n",
        "\n",
        "def show_collage(examples):\n",
        "    box_size = height_width + 2\n",
        "    num_rows, num_cols = examples.shape[:2]\n",
        "\n",
        "    collage = Image.new(\n",
        "        mode=\"RGB\",\n",
        "        size=(num_cols * box_size, num_rows * box_size),\n",
        "        color=(250, 250, 250),\n",
        "    )\n",
        "    for row_idx in range(num_rows):\n",
        "        for col_idx in range(num_cols):\n",
        "            array = (np.array(examples[row_idx, col_idx])).astype(np.uint8)\n",
        "            collage.paste(\n",
        "                Image.fromarray(array), (col_idx * box_size, row_idx * box_size)\n",
        "            )\n",
        "\n",
        "    # Double size for visualisation.\n",
        "    collage = collage.resize((2 * num_cols * box_size, 2 * num_rows * box_size))\n",
        "    return collage\n",
        "\n",
        "\n",
        "# Show a collage of 5x5 random images.\n",
        "sample_idxs = np.random.randint(0, 50000, size=(5, 5))\n",
        "examples = x_train[sample_idxs]\n",
        "show_collage(examples)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用transfer learning 前處理\n",
        "preprocess = keras.applications.mobilenet_v2.preprocess_input\n",
        "\n",
        "x_train = preprocess(x_train)\n",
        "x_test = preprocess(x_test)"
      ],
      "metadata": {
        "id": "VfdoJNgaHHbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vfVSGq_vfaI"
      },
      "outputs": [],
      "source": [
        "# 建構各類別對應影像位置\n",
        "class_idx_to_train_idxs = defaultdict(list)\n",
        "for y_train_idx, y in enumerate(y_train):\n",
        "    class_idx_to_train_idxs[y].append(y_train_idx)\n",
        "\n",
        "class_idx_to_test_idxs = defaultdict(list)\n",
        "for y_test_idx, y in enumerate(y_test):\n",
        "    class_idx_to_test_idxs[y].append(y_test_idx)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# key: 類別\n",
        "class_idx_to_test_idxs.keys()"
      ],
      "metadata": {
        "id": "cMkoh2EKx3nP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# value: 此類別的圖片在第幾張\n",
        "class_idx_to_test_idxs[0][:5]"
      ],
      "metadata": {
        "id": "SXGYJL4Oya4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "目標：\n",
        "\n",
        "在一個batch中\n",
        "\n",
        "1. 拉近anchor, positive\n",
        "\n",
        "2. 拉開anchor, negative\n",
        "\n",
        "這邊的batch size跟類別個數相同 e.g: CIFAR10 = 10"
      ],
      "metadata": {
        "id": "j_BnrXph2aVk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJ3UUm_NvfaJ"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "\n",
        "class AnchorPositivePairs(keras.utils.Sequence):\n",
        "    def __init__(self, num_batchs):\n",
        "        self.num_batchs = num_batchs\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_batchs\n",
        "\n",
        "    def __getitem__(self, _idx):\n",
        "        x = np.empty((2, num_classes, height_width, height_width, 3), dtype=np.float32)\n",
        "        # 將每個類別依序取出\n",
        "        for class_idx in range(num_classes):\n",
        "            examples_for_class = class_idx_to_train_idxs[class_idx]\n",
        "            # 隨機選擇 anchor, positive 位置各一\n",
        "            anchor_idx = random.choice(examples_for_class)\n",
        "            positive_idx = random.choice(examples_for_class)\n",
        "            # 若剛好anchor 與 positive 是同一張，持續隨機選擇\n",
        "            while positive_idx == anchor_idx:\n",
        "                positive_idx = random.choice(examples_for_class)\n",
        "            # 將anchor, positive 圖片放到對應的類別\n",
        "            x[0, class_idx] = x_train[anchor_idx]\n",
        "            x[1, class_idx] = x_train[positive_idx]\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUcjbfSjvfaK"
      },
      "source": [
        "視覺化一個batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIQ06EFxvfaK"
      },
      "outputs": [],
      "source": [
        "examples = AnchorPositivePairs(num_batchs=1)[0]\n",
        "examples = ((examples/2 + 0.5) * 255).astype(int) # -1~1 -> 0~255\n",
        "print(\"examples shape\", examples.shape)\n",
        "show_collage(examples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFhA3f_YvfaL"
      },
      "source": [
        "## Embedding model\n",
        "\n",
        "客製化Model的`train_step`\n",
        "\n",
        "1. 取出anchor & positive 的embedding 向量\n",
        "\n",
        "2. 計算anchor & positive 向量內積"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHZbiC15vfaL"
      },
      "outputs": [],
      "source": [
        "\n",
        "class EmbeddingModel(keras.Model):\n",
        "    def train_step(self, data):\n",
        "        # Note: Workaround for open issue, to be removed.\n",
        "        if isinstance(data, tuple):\n",
        "            data = data[0]\n",
        "        anchors, positives = data[0], data[1]\n",
        "        # data: (2, N, H, W, C)\n",
        "        # anchor, postive: (N, H, W, C)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # 計算 anchors, positives 的 embedding\n",
        "            # anchor, positive embedding: (N, dim)\n",
        "            anchor_embeddings = self(anchors, training=True)\n",
        "            positive_embeddings = self(positives, training=True)\n",
        "\n",
        "            # 用內積計算anchors, positives 相似度\n",
        "            # similarities: (N, N)\n",
        "            similarities = tf.einsum(\n",
        "                \"ae,pe->ap\", anchor_embeddings, positive_embeddings\n",
        "            )\n",
        "\n",
        "            # 用超參數temperature做normalize\n",
        "            temperature = 0.2\n",
        "            similarities /= temperature\n",
        "\n",
        "            # 解答為N類別index: [0, 1, 2, ..., num_classes-1]\n",
        "            # 解答形式為對角矩陣\n",
        "            # e.g 3類別:\n",
        "            # [1, 0, 0]\n",
        "            # [0, 1, 0]\n",
        "            # [0, 0, 1]\n",
        "            sparse_labels = tf.range(num_classes)\n",
        "            loss = self.compiled_loss(sparse_labels, similarities)\n",
        "\n",
        "        # 計算梯度+更新參數\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "\n",
        "        # 更新metrics\n",
        "        self.compiled_metrics.update_state(sparse_labels, similarities)\n",
        "        return {m.name: m.result() for m in self.metrics}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yD7_MCVvfaL"
      },
      "source": [
        "建造模型\n",
        "\n",
        "抽取特徵後將輸入投影至dim=8空間，再normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpKkw2yivfaM"
      },
      "outputs": [],
      "source": [
        "inputs = layers.Input(shape=(height_width, height_width, 3))\n",
        "encoder = keras.applications.MobileNetV2(include_top=False, \n",
        "                                         weights='imagenet',\n",
        "                                         input_shape=(height_width, height_width, 3))\n",
        "x = encoder(inputs)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "embeddings = layers.Dense(units=8, activation=None)(x)\n",
        "embeddings = tf.nn.l2_normalize(embeddings, axis=-1)\n",
        "# 用上面EmbeddingModel封裝模型\n",
        "model = EmbeddingModel(inputs, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "CSKAS0MBJdWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deF7nbt7vfaM"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        ")\n",
        "# 1個epoch 1000 batches\n",
        "history = model.fit(AnchorPositivePairs(num_batchs=1000), \n",
        "                    epochs=20)\n",
        "\n",
        "plt.plot(history.history[\"loss\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights(\"mobilev2_metric_32.h5\")"
      ],
      "metadata": {
        "id": "UbxmQJxuKKuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzbiBIt_vfaM"
      },
      "source": [
        "## Testing\n",
        "\n",
        "1. 計算整個test_set的圖片embedding\n",
        "2. 計算test圖片兩兩間的相似度 "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -L https://github.com/taipingeric/ML-for-Newbies/releases/download/0.0.1/mobilev2_metric_32.h5 > mobilev2_metric_32.h5"
      ],
      "metadata": {
        "id": "PvB20RY9ig7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(\"mobilev2_metric_32.h5\")"
      ],
      "metadata": {
        "id": "9lTyfSAGdoMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVfO523GvfaM"
      },
      "outputs": [],
      "source": [
        "near_neighbours_per_example = 10\n",
        "\n",
        "embeddings = model.predict(x_test)\n",
        "# 計算圖片兩兩間的內積\n",
        "gram_matrix = np.einsum(\"ae,be->ab\", embeddings, embeddings)\n",
        "# 計算每一筆資料相似度排序最高的10筆結果 (小->大)\n",
        "# 最大值就是自己本身 (100%相似)\n",
        "near_neighbours = np.argsort(gram_matrix.T)[:, -(near_neighbours_per_example + 1) :]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.shape, gram_matrix.shape, near_neighbours.shape"
      ],
      "metadata": {
        "id": "V6TYx7aizvGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "    print(near_neighbours[i])"
      ],
      "metadata": {
        "id": "dOPDhaGCz-fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zPDwgsUvfaM"
      },
      "source": [
        "column 0: 原始查詢圖片\n",
        "\n",
        "column 1~10: 資料庫中最接近的圖片 以相似度排序大->小"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Epzi9XW3vfaN"
      },
      "outputs": [],
      "source": [
        "num_collage_examples = 5\n",
        "\n",
        "examples = np.empty(\n",
        "    (\n",
        "        num_collage_examples,\n",
        "        near_neighbours_per_example + 1,\n",
        "        height_width,\n",
        "        height_width,\n",
        "        3,\n",
        "    ),\n",
        "    dtype=np.float32,\n",
        ")\n",
        "for row_idx in range(num_collage_examples):\n",
        "    examples[row_idx, 0] = x_test_raw[row_idx]\n",
        "    anchor_near_neighbours = reversed(near_neighbours[row_idx][:-1])\n",
        "    for col_idx, nn_idx in enumerate(anchor_near_neighbours):\n",
        "        examples[row_idx, col_idx + 1] = x_test_raw[nn_idx]\n",
        "\n",
        "show_collage(examples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nya9paVLvfaN"
      },
      "source": [
        "計算各類別中，每張圖片與最接近該圖片的類別是否為同一個，計算混淆矩陣"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnB2-yzVvfaN"
      },
      "outputs": [],
      "source": [
        "confusion_matrix = np.zeros((num_classes, num_classes))\n",
        "\n",
        "# For each class.\n",
        "for class_idx in range(num_classes):\n",
        "    # 挑選10筆資料\n",
        "    example_idxs = class_idx_to_test_idxs[class_idx][:10]\n",
        "    for y_test_idx in example_idxs:\n",
        "        # 計算與該圖片最相似的圖片類別\n",
        "        for nn_idx in near_neighbours[y_test_idx][:-1]:\n",
        "            nn_class_idx = y_test[nn_idx]\n",
        "            confusion_matrix[class_idx, nn_class_idx] += 1\n",
        "\n",
        "# 顯示混淆矩陣\n",
        "labels = [\n",
        "    \"Airplane\",\n",
        "    \"Automobile\",\n",
        "    \"Bird\",\n",
        "    \"Cat\",\n",
        "    \"Deer\",\n",
        "    \"Dog\",\n",
        "    \"Frog\",\n",
        "    \"Horse\",\n",
        "    \"Ship\",\n",
        "    \"Truck\",\n",
        "]\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix, display_labels=labels)\n",
        "disp.plot(include_values=True, cmap=\"viridis\", ax=None, xticks_rotation=\"vertical\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ref: \n",
        "* [What is metric learning?](http://contrib.scikit-learn.org/metric-learn/introduction.html)\n",
        "* [\"Using crossentropy for metric learning\" tutorial](https://www.youtube.com/watch?v=Jb4Ewl5RzkI)"
      ],
      "metadata": {
        "id": "TY1J7TX8wUCE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPpdt6DUvfaN"
      },
      "source": [
        "Example available on HuggingFace.\n",
        "\n",
        "| Trained Model | Demo |\n",
        "| :--: | :--: |\n",
        "| [![Generic badge](https://img.shields.io/badge/🤗%20Model-Cifar10%20Metric%20Learning-black.svg)](https://huggingface.co/keras-io/cifar10_metric_learning) | [![Generic badge](https://img.shields.io/badge/🤗%20Spaces-Metric%20Learning%20for%20Image%20Similarity%20Search-black.svg)](https://huggingface.co/spaces/keras-io/metric-learning-image-similarity-search) |"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}